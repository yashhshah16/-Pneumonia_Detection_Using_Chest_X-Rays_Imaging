{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "import scikitplot as skplt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "import timeit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, ShuffleSplit\n",
    "import mahotas\n",
    "import pickle\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-1: Hu Moments\n",
    "def fd_hu_moments(image):\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(image):\n",
    "    haralick = mahotas.features.haralick(image).mean(axis=0)\n",
    "    return haralick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1341/1341 [02:56<00:00,  7.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3875/3875 [05:33<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "IMG_SIZE =500\n",
    "CATEGORIES = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "DATADIR = \"C:/Users/yashh/Data Analytics/Project/chest-xray-pneumonia/chest_xray/train\"\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,category) \n",
    "        class_num = CATEGORIES.index(category) \n",
    "\n",
    "        for img in tqdm(os.listdir(path)): \n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "\n",
    "                fv_hu_moments = fd_hu_moments(new_array)\n",
    "                fv_haralick   = fd_haralick(new_array)\n",
    "\n",
    "                global_feature = np.hstack([fv_haralick, fv_hu_moments])\n",
    "                #haralick = mahotas.features.haralick(new_array).mean(axis=0)\n",
    "                #histogram_features, hist_image= hog(new_array, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "        \n",
    "                training_data.append([global_feature,class_num]) \n",
    "            except Exception as e:  \n",
    "                pass\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:17<00:00, 13.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 390/390 [00:19<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624\n"
     ]
    }
   ],
   "source": [
    "testing_data = []\n",
    "IMG_SIZE =200\n",
    "CATEGORIES = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "DATADIR = \"C:/Users/yashh/Data Analytics/Project/chest-xray-pneumonia/chest_xray/test\"\n",
    "\n",
    "def create_testing_data():\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,category) \n",
    "        class_num = CATEGORIES.index(category) \n",
    "\n",
    "        for img in tqdm(os.listdir(path)): \n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "\n",
    "                fv_hu_moments = fd_hu_moments(new_array)\n",
    "                fv_haralick   = fd_haralick(new_array)\n",
    "\n",
    "                global_feature = np.hstack([fv_haralick, fv_hu_moments])\n",
    "                #haralick = mahotas.features.haralick(new_array).mean(axis=0)\n",
    "                #histogram_features, hist_image= hog(new_array, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "        \n",
    "                testing_data.append([global_feature,class_num]) \n",
    "            except Exception as e:  \n",
    "                pass\n",
    "\n",
    "create_testing_data()\n",
    "\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1575/1575 [02:06<00:00, 12.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4265/4265 [01:55<00:00, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5840\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "IMG_SIZE =200\n",
    "CATEGORIES = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "DATADIR = \"C:/Users/yashh/Data Analytics/Project/chest-xray-pneumonia/chest_xray/all\"\n",
    "\n",
    "def create_data():\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,category) \n",
    "        class_num = CATEGORIES.index(category) \n",
    "\n",
    "        for img in tqdm(os.listdir(path)): \n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "\n",
    "                fv_hu_moments = fd_hu_moments(new_array)\n",
    "                fv_haralick   = fd_haralick(new_array)\n",
    "\n",
    "                global_feature = np.hstack([fv_haralick, fv_hu_moments])\n",
    "                #haralick = mahotas.features.haralick(new_array).mean(axis=0)\n",
    "                #histogram_features, hist_image= hog(new_array, orientations=8, pixels_per_cell=(16, 16), cells_per_block=(1, 1), visualize=True)\n",
    "        \n",
    "                data.append([global_feature,class_num]) \n",
    "            except Exception as e:  \n",
    "                pass\n",
    "\n",
    "create_data()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(testing_data)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"SVM_data.pickle\",\"wb\")\n",
    "pickle.dump(data, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data= pickle.load(open(\"SVM_train.pickle\",\"rb\"))\n",
    "testing_data= pickle.load(open(\"SVM_test.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features,label in testing_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = StandardScaler()\n",
    "pre_process.fit(X)\n",
    "X = pre_process.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = StandardScaler()\n",
    "pre_process.fit(X_test)\n",
    "X_test = pre_process.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.2%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "num_trees=100\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=16)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=5, random_state=16)\n",
    "results = cross_val_score(model, X, y, cv=cv)\n",
    "print(f\"Accuracy: {round(results.mean()*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=5,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=16, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-16be0a6fbeb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpickle_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RF_model.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pickle_out = open(\"RF_model.pickle\",\"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators':list(range(50,500,50)),\n",
    "             'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [5,10,15,20],\n",
    "             'min_samples_split': list(range(3,10)),\n",
    "             'min_samples_leaf': [1,5,10,15,20]}\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid, cv=6, verbose=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,...\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 10, 15, 20],\n",
       "                         'min_samples_leaf': [1, 5, 10, 15, 20],\n",
       "                         'min_samples_split': [3, 4, 5, 6, 7, 8, 9],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300, 350, 400,\n",
       "                                          450]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029919447640967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 15,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 350}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'criterion': 'entropy',\n",
    " 'max_depth': 15,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 4,\n",
    " 'n_estimators': 350}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(criterion= 'entropy', max_depth= 15, min_samples_leaf= 1, min_samples_split= 4,n_estimators= 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=4,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7756410256410257\n",
      "Recall: 0.9435897435897436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.50      0.62       234\n",
      "           1       0.76      0.94      0.84       390\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.80      0.72      0.73       624\n",
      "weighted avg       0.79      0.78      0.76       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, pred)}\")\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"NORMAL\",\"PNEUMONIA\"]\n",
    "disp = plot_confusion_matrix(model.fit(X,y), X_test, y_test,\n",
    "                                 display_labels=CATEGORIES,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=None)\n",
    "disp.ax_.set_title(\"Chest X-Ray Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    standardized_data = StandardScaler()\n",
    "    pca = PCA(n_components=10)\n",
    "    svc = SVC()\n",
    "    pipe = Pipeline([('standardized_data', standardized_data),\n",
    "                     ('pca', pca),\n",
    "                     ('svc', svc)])\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    svm_parameters = [{'svc__C':[0.1,1.,10.,100.], 'svc__kernel':['rbf'], 'svc__gamma':[0.1,1.,10.,100.], \n",
    "                       'svc__probability':[True], 'svc__random_state':[155]}]  \n",
    "    grid_search_svm = GridSearchCV(pipe, svm_parameters, cv=3, n_jobs=4)\n",
    "    grid_search_svm.fit(train_x, train_y)\n",
    "    print(f'Runtime for SVM:{timeit.default_timer() - start}')\n",
    "    return grid_search_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = grid_search()\n",
    "svm_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =SVC(C= 1.0,gamma= 0.1, kernel='rbf',probability=True,random_state= 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x_stand,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(test_y, svm_results)}\")\n",
    "print(f\"Recall: {recall_score(test_y, svm_results)}\")\n",
    "print(classification_report(test_y, svm_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(probs, label):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    # results = [n for n in np.ravel(test_y) if n == label]\n",
    "    for i in range(2):  #  binary classifier\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_y, probs[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        print(roc_auc[i])\n",
    "        \n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_y.ravel(), svm_results.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr[label], tpr[label], color='darkorange', lw=2, label='ROC curve {:.2f}'.format(roc_auc[label]))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = svm_model.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_roc(test_y, predict_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
